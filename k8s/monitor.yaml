apiVersion: v1
kind: Secret
metadata:
  name: s3-log-keys
  namespace: ${KUBE_NAMESPACE}
type: Opaque
data:
  AWS_ACCESS_KEY_ID: ${SCW_LOG_ACCESS_KEY_B64}
  AWS_SECRET_ACCESS_KEY: ${SCW_LOG_SECRET_KEY_B64}
---
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: monitor
  namespace: monitor
spec:
  version: ${ELASTIC_VERSION}
  volumeClaimDeletePolicy: ${ELASTIC_STORAGE_POLICY}
  nodeSets:
  - name: default
    count: ${ELASTIC_NODES}
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: ${ELASTIC_STORAGE_SIZE}
    podTemplate:
      spec:
        initContainers:
        - name: sysctl
          securityContext:
            privileged: true
          command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
        containers:
        - name: elasticsearch
          env:
          - name: ES_JAVA_OPTS
            value: -Xms${ELASTIC_MEM_JVM} -Xmx${ELASTIC_MEM_JVM}
          resources:
            requests:
              memory: ${ELASTIC_MEM}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-configmap
  namespace: monitor
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
  logstash.conf: |
    input {
      s3 {
        access_key_id => "${AWS_ACCESS_KEY_ID}"
        secret_access_key => "${AWS_SECRET_ACCESS_KEY}"
        bucket => "${SCW_LOG_BUCKET}"
        additional_settings => {
          force_path_style => true
          follow_redirects => false
        }
        region => "${SCW_REGION}"
        endpoint => "https://s3.${SCW_REGION}.scw.cloud"
        exclude_pattern => "konnectivity-agent"
        codec => "json_lines"
      }
    }
    filter {
      date {
        match => [ "date" , "ISO8601" ]
      }
      grok {
        match => {
          "[kubernetes][host]" => "^(?<kubernetes_cluster_name>.*)-default-[^\-]*$"
        }
        tag_on_failure => [ "kubernetes_cluster_name_error" ]
      }
      mutate {
        rename => {
          "[kubernetes_cluster_name]" => "[kubernetes][cluster_name]"
          "[kubernetes][labels][app]" => "[kubernetes][labels][app.kubernetes.io/name]"
        }
      }
      grok {
        match => {
          "log" => "%{TIMESTAMP_ISO8601:container_timestamp} %{WORD:container_output} %{WORD:container_output_mode} %{GREEDYDATA:container_log}"
        }
        tag_on_failure => [ "kubernetes_log_parse_error" ]
      }
      if [container_output] {
          mutate {
            remove_field => ["log"]
          }
        if [container_output] == "stderr" {
          mutate {
            add_tag => ["container_error"]
          }
        }
        if [kubernetes][container_name] == "nginx-ingress-controller" {
          if [container_output] != "stderr" {
            mutate {
              add_field => { "log_type" => "web_access" }
            }
            grok {
              match => { "container_log" => "%{IPORHOST:clientip} (?:-|(%{WORD}.%{WORD})) (-|%{USER:http_user}) \[%{HTTPDATE:timestamp_request}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:status;long} (?:%{NUMBER:body_bytes_sent;long}|-) (?:\"(?:%{URI:http_referrer}|-)\") \"%{DATA:http_user_agent}\" %{NUMBER:request_length;long} %{NUMBER:request_time;double} \[(?:%{DATA:proxy_upstream_name})\] \[(?:%{DATA:proxy_alternative_upstream_name})\] (-|%{NOTSPACE:upstream_addr}) (-|%{NUMBER:upstream_response_length;long}) (-|%{NUMBER:upstream_response_time;double}) (-|%{NUMBER:upstream_status;long}) %{NOTSPACE:request_id}" }
            }
            if "_grokparsefailure" in [tags] {
              mutate {
                add_tag => [ "nginx_log_parse_error" ]
              }
            } else {
              mutate {
                remove_field => ["container_log"]
              }
              geoip {
                source => "clientip"
              }
            }
          } else {
            mutate {
              add_field => { "log_type" => "web_error" }
            }
          }
        } else if [kubernetes][container_name] == "judilibre-search-deployment" {
          mutate {
            add_field => { "log_type" => "judilibre-search" }
          }
        } else if [kubernetes][container_name] == "judilibre-admin-deployment" {
          mutate {
            add_field => { "log_type" => "judilibre-admin" }
          }
        } else if [kubernetes][container_name] =~ /^judilibre-es-.*/ {
          mutate {
            add_field => { "log_type" => "elasticsearch" }
          }
        } else {
          mutate {
            add_field => { "log_type" => "kubernetes" }
          }
        }
      } else {
        mutate {
          add_field => { "log_type" => "unparsed" }
        }
      }
    }
    output {
      elasticsearch {
        index => "logstash-%{[kubernetes][cluster_name]}-%{[log_type]}-%{+YYYY.MM}"
        user => "elastic"
        password => "${ELASTIC_PASSWORD}"
        hosts => ["https://monitor-es-http:9200"]
        cacert => "/etc/logstash/certificates/ca.crt"
        ssl => true
        action => "create"
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash-deployment
  namespace: monitor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
    spec:
      initContainers:
      - name: install-plugins
        image: docker.elastic.co/logstash/logstash:7.14.0
        command:
        - sh
        - -c
        - |
          bin/logstash-plugin install logstash-codec-json_lines
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:7.14.0
        ports:
        - containerPort: 5044
        env:
          - name: ELASTIC_PASSWORD
            valueFrom:
              secretKeyRef:
                name: ${APP_GROUP}-es-elastic-user
                key: elastic
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: s3-log-keys
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: s3-log-keys
                key: AWS_SECRET_ACCESS_KEY
        volumeMounts:
          - name: config-volume
            mountPath: /usr/share/logstash/config
          - name: logstash-pipeline-volume
            mountPath: /usr/share/logstash/pipeline
          - name: cert-ca
            mountPath: /etc/logstash/certificates
            readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: logstash-configmap
          items:
            - key: logstash.yml
              path: logstash.yml
      - name: logstash-pipeline-volume
        configMap:
          name: logstash-configmap
          items:
            - key: logstash.conf
              path: logstash.conf
      - name: cert-ca
        secret:
          secretName: monitor-es-http-certs-public
---
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: monitor
  namespace: monitor
spec:
  version: 7.14.0
  count: 1
  elasticsearchRef:
    name: monitor
